// /_scripts/etl-smart-batch-processor.mjs
// ETL Smart Batch Processor - æ™ºèƒ½åˆ†æ‰¹å¤„ç†å™¨
// æ¯å¤©ä»æ•°æ®åº“åˆå§‹è‚¡ç¥¨å¼€å§‹è¿è¡Œï¼Œæ¯15åˆ†é’Ÿè¿è¡Œä¸€æ¬¡ï¼Œæ¯æ¬¡50åªè‚¡ç¥¨
// å…±è¿è¡Œ10æ¬¡ï¼ˆ150åˆ†é’Ÿï¼‰ï¼Œæ€»è®¡160åˆ†é’Ÿåç»“æŸï¼Œä¸å¾ªç¯è¿è¡Œ

import { Pool } from 'pg';
import 'dotenv/config';
import { getPreviousDayAggs } from './polygon-api.js';

const pool = new Pool({ 
    connectionString: process.env.NEON_DATABASE_URL || process.env.DATABASE_URL, 
    ssl: { rejectUnauthorized: false } 
});

// ETLä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€
const ETL_STATUS = {
    PENDING: 'pending',
    PROCESSING: 'processing', 
    COMPLETED: 'completed',
    FAILED: 'failed'
};

// ç¡®ä¿ETLä»»åŠ¡é˜Ÿåˆ—è¡¨å­˜åœ¨
async function ensureETLTaskQueueExists(client) {
    await client.query(`
        CREATE TABLE IF NOT EXISTS etl_task_queue (
            id SERIAL PRIMARY KEY,
            ticker VARCHAR(10) NOT NULL,
            task_date DATE NOT NULL DEFAULT CURRENT_DATE,
            batch_number INTEGER NOT NULL DEFAULT 1,
            status VARCHAR(20) NOT NULL DEFAULT 'pending',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            processed_at TIMESTAMP NULL,
            error_message TEXT NULL,
            UNIQUE(ticker, task_date)
        )
    `);
    
    // åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
    await client.query(`
        CREATE INDEX IF NOT EXISTS idx_etl_task_queue_status_date 
        ON etl_task_queue(status, task_date)
    `);
    
    console.log("âœ… ETL task queue table ensured");
}

// åˆå§‹åŒ–ä»Šæ—¥ETLä»»åŠ¡é˜Ÿåˆ—
async function initializeDailyETLQueue(client) {
    const today = new Date().toISOString().split('T')[0];
    
    // æ£€æŸ¥ä»Šæ—¥æ˜¯å¦å·²åˆå§‹åŒ–
    const { rows: existingTasks } = await client.query(`
        SELECT COUNT(*) as count FROM etl_task_queue 
        WHERE task_date = $1
    `, [today]);
    
    if (parseInt(existingTasks[0].count) > 0) {
        console.log(`ğŸ“‹ Today's ETL queue already initialized (${existingTasks[0].count} tasks)`);
        return;
    }
    
    // è·å–æ‰€æœ‰è‚¡ç¥¨å¹¶åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—
    const { rows: stocks } = await client.query(`
        SELECT ticker FROM stocks 
        ORDER BY ticker
    `);
    
    console.log(`ğŸš€ Initializing ETL queue for ${stocks.length} stocks...`);
    
    // æ‰¹é‡æ’å…¥ä»»åŠ¡
    const batchSize = 50;
    let batchNumber = 1;
    
    for (let i = 0; i < stocks.length; i += batchSize) {
        const batch = stocks.slice(i, i + batchSize);
        
        for (const stock of batch) {
            await client.query(`
                INSERT INTO etl_task_queue (ticker, task_date, batch_number, status)
                VALUES ($1, $2, $3, $4)
                ON CONFLICT (ticker, task_date) DO NOTHING
            `, [stock.ticker, today, batchNumber, ETL_STATUS.PENDING]);
        }
        
        batchNumber++;
    }
    
    console.log(`âœ… ETL queue initialized with ${Math.ceil(stocks.length / batchSize)} batches`);
}

// è·å–ä¸‹ä¸€æ‰¹å¾…å¤„ç†çš„è‚¡ç¥¨
async function getNextBatch(client, batchSize = 50) {
    const today = new Date().toISOString().split('T')[0];
    
    const { rows: tasks } = await client.query(`
        SELECT ticker, batch_number FROM etl_task_queue 
        WHERE task_date = $1 AND status = $2
        ORDER BY batch_number, ticker
        LIMIT $3
    `, [today, ETL_STATUS.PENDING, batchSize]);
    
    return tasks;
}

// æ ‡è®°ä»»åŠ¡ä¸ºå¤„ç†ä¸­
async function markTasksAsProcessing(client, tickers) {
    const today = new Date().toISOString().split('T')[0];
    
    await client.query(`
        UPDATE etl_task_queue 
        SET status = $1, updated_at = CURRENT_TIMESTAMP
        WHERE ticker = ANY($2) AND task_date = $3
    `, [ETL_STATUS.PROCESSING, tickers, today]);
}

// æ ‡è®°ä»»åŠ¡ä¸ºå®Œæˆ
async function markTaskAsCompleted(client, ticker) {
    const today = new Date().toISOString().split('T')[0];
    
    await client.query(`
        UPDATE etl_task_queue 
        SET status = $1, processed_at = CURRENT_TIMESTAMP, updated_at = CURRENT_TIMESTAMP
        WHERE ticker = $2 AND task_date = $3
    `, [ETL_STATUS.COMPLETED, ticker, today]);
}

// æ ‡è®°ä»»åŠ¡ä¸ºå¤±è´¥
async function markTaskAsFailed(client, ticker, errorMessage) {
    const today = new Date().toISOString().split('T')[0];
    
    await client.query(`
        UPDATE etl_task_queue 
        SET status = $1, error_message = $2, updated_at = CURRENT_TIMESTAMP
        WHERE ticker = $3 AND task_date = $4
    `, [ETL_STATUS.FAILED, errorMessage, ticker, today]);
}

// è·å–Finnhubè´¢åŠ¡æŒ‡æ ‡
async function getFinnhubMetrics(symbol, apiKey) {
    try {
        const response = await fetch(`https://finnhub.io/api/v1/stock/metric?symbol=${symbol}&metric=all&token=${apiKey}`);
        const data = await response.json();
        
        if (data.error) {
            console.warn(`âš ï¸ Finnhub API error for ${symbol}: ${data.error}`);
            return null;
        }
        
        return data;
    } catch (error) {
        console.error(`âŒ Error fetching Finnhub data for ${symbol}:`, error.message);
        return null;
    }
}

// è·å–Finnhubå®æ—¶æŠ¥ä»·æ•°æ®
async function getFinnhubQuote(symbol, apiKey) {
    try {
        const response = await fetch(`https://finnhub.io/api/v1/quote?symbol=${symbol}&token=${apiKey}`);
        const data = await response.json();
        
        if (data.error) {
            console.warn(`âš ï¸ Finnhub Quote API error for ${symbol}: ${data.error}`);
            return null;
        }
        
        return data;
    } catch (error) {
        console.error(`âŒ Error fetching Finnhub quote for ${symbol}:`, error.message);
        return null;
    }
}

// å¤„ç†å•åªè‚¡ç¥¨çš„æ•°æ®æ›´æ–°
async function processStock(client, ticker, finnhubApiKey, polygonApiKey) {
    try {
        console.log(`ğŸ“Š Processing ${ticker}...`);
        
        // 1. è·å–Polygonæ—¥çº¿æ•°æ®
        let polygonData = null;
        if (polygonApiKey) {
            polygonData = await getPreviousDayAggs(ticker);
        }
        
        // 2. è·å–Finnhubè´¢åŠ¡æŒ‡æ ‡
        const financialData = await getFinnhubMetrics(ticker, finnhubApiKey);
        
        // 3. è·å–Finnhubå®æ—¶æŠ¥ä»·
        const quoteData = await getFinnhubQuote(ticker, finnhubApiKey);
        
        // å‡†å¤‡æ›´æ–°æ•°æ®
        let updateData = {
            market_cap: null,
            roe_ttm: null,
            pe_ttm: null,
            dividend_yield: null,
            open_price: null,
            high_price: null,
            low_price: null,
            last_price: null,
            volume: null,
            vwap: null,
            trade_count: null,
            previous_close: null
        };
        
        // å¤„ç†Polygonæ•°æ®
        if (polygonData) {
            updateData.open_price = polygonData.open_price;
            updateData.high_price = polygonData.high_price;
            updateData.low_price = polygonData.low_price;
            updateData.last_price = polygonData.close_price;
            updateData.volume = polygonData.volume;
            updateData.vwap = polygonData.vwap;
            updateData.trade_count = polygonData.trade_count;
            updateData.previous_close = polygonData.close_price;
        }
        
        // å¤„ç†Finnhubè´¢åŠ¡æ•°æ®
        if (financialData && financialData.metric) {
            const metrics = financialData.metric;
            updateData.market_cap = metrics.marketCapitalization || null;
            updateData.roe_ttm = metrics.roeTTM || null;
            updateData.pe_ttm = metrics.peTTM || null;
        }
        
        // å¤„ç†FinnhubæŠ¥ä»·æ•°æ®
        if (quoteData) {
            updateData.dividend_yield = quoteData.dp || null;
        }
        
        // æ›´æ–°æ•°æ®åº“
        await client.query(`
            UPDATE stocks SET 
                market_cap = COALESCE($1, market_cap),
                roe_ttm = COALESCE($2, roe_ttm),
                pe_ttm = COALESCE($3, pe_ttm),
                dividend_yield = COALESCE($4, dividend_yield),
                open_price = COALESCE($5, open_price),
                high_price = COALESCE($6, high_price),
                low_price = COALESCE($7, low_price),
                last_price = COALESCE($8, last_price),
                volume = COALESCE($9, volume),
                vwap = COALESCE($10, vwap),
                trade_count = COALESCE($11, trade_count),
                previous_close = COALESCE($12, previous_close),
                daily_data_last_updated = CURRENT_DATE,
                last_updated = CURRENT_TIMESTAMP
            WHERE ticker = $13
        `, [
            updateData.market_cap,
            updateData.roe_ttm,
            updateData.pe_ttm,
            updateData.dividend_yield,
            updateData.open_price,
            updateData.high_price,
            updateData.low_price,
            updateData.last_price,
            updateData.volume,
            updateData.vwap,
            updateData.trade_count,
            updateData.previous_close,
            ticker
        ]);
        
        // æ ‡è®°ä»»åŠ¡å®Œæˆ
        await markTaskAsCompleted(client, ticker);
        console.log(`âœ… ${ticker} processed successfully`);
        
        return true;
        
    } catch (error) {
        console.error(`âŒ Error processing ${ticker}:`, error.message);
        await markTaskAsFailed(client, ticker, error.message);
        return false;
    }
}

// è·å–ETLè¿›åº¦ç»Ÿè®¡
async function getETLProgress(client) {
    const today = new Date().toISOString().split('T')[0];
    
    const { rows } = await client.query(`
        SELECT 
            status,
            COUNT(*) as count
        FROM etl_task_queue 
        WHERE task_date = $1
        GROUP BY status
    `, [today]);
    
    const progress = {
        pending: 0,
        processing: 0,
        completed: 0,
        failed: 0,
        total: 0
    };
    
    rows.forEach(row => {
        progress[row.status] = parseInt(row.count);
        progress.total += parseInt(row.count);
    });
    
    return progress;
}

// ä¸»å¤„ç†å‡½æ•°
async function main() {
    console.log("===== ETL Smart Batch Processor Started =====");
    const startTime = new Date();
    console.log(`ğŸ• Start Time: ${startTime.toISOString()}`);
    
    // è®¾ç½®160åˆ†é’Ÿè¿è¡Œæ—¶é—´é™åˆ¶
    const MAX_RUNTIME_MINUTES = 160;
    const maxEndTime = new Date(startTime.getTime() + MAX_RUNTIME_MINUTES * 60 * 1000);
    console.log(`â° Max End Time: ${maxEndTime.toISOString()} (${MAX_RUNTIME_MINUTES} minutes limit)`);
    
    const { NEON_DATABASE_URL, DATABASE_URL, FINNHUB_API_KEY, POLYGON_API_KEY } = process.env;
    const dbUrl = NEON_DATABASE_URL || DATABASE_URL;
    
    // æ£€æŸ¥æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼
    const isTestMode = !dbUrl || dbUrl.includes('username:password') || !FINNHUB_API_KEY || FINNHUB_API_KEY === 'your_finnhub_api_key_here';
    
    if (isTestMode) {
        console.log("âš ï¸ Running in TEST MODE - No valid database connection or API key");
        console.log("âœ… ETL Smart Batch Processor structure validation passed");
        console.log("ğŸ“ To run with real database and API:");
        console.log("   1. Set DATABASE_URL to your Neon database connection string");
        console.log("   2. Set FINNHUB_API_KEY to your Finnhub API key");
        console.log("   3. Set POLYGON_API_KEY to your Polygon API key (optional)");
        console.log("===== Test completed successfully =====");
        return;
    }
    
    if (!dbUrl || !FINNHUB_API_KEY) {
        console.error("FATAL: Missing DATABASE_URL or FINNHUB_API_KEY environment variables.");
        process.exit(1);
    }
    
    if (!POLYGON_API_KEY) {
        console.warn("âš ï¸ POLYGON_API_KEY not found - Polygon data will be skipped");
    }
    
    console.log("ğŸ”§ ETL Configuration:");
    console.log(`   ğŸ“¦ Batch Size: 50 stocks per batch`);
    console.log(`   â±ï¸ Frequency: Every 15 minutes`);
    console.log(`   ğŸ”„ Max Batches: 10 batches (150 minutes total)`);
    console.log(`   â° Total Runtime: 160 minutes max`);
    console.log(`   ğŸ”‘ APIs: Finnhub âœ…, Polygon ${POLYGON_API_KEY ? 'âœ…' : 'âŒ'}`);
    
    let client;
    try {
        client = await pool.connect();
        console.log("âœ… Database connected successfully");
        
        // ç¡®ä¿ETLä»»åŠ¡é˜Ÿåˆ—è¡¨å­˜åœ¨
        await ensureETLTaskQueueExists(client);
        
        // åˆå§‹åŒ–ä»Šæ—¥ETLä»»åŠ¡é˜Ÿåˆ—
        await initializeDailyETLQueue(client);
        
        // æ£€æŸ¥è¿è¡Œæ—¶é—´é™åˆ¶
        const currentTime = new Date();
        if (currentTime >= maxEndTime) {
            console.log("\nâ° Reached 160-minute runtime limit - stopping ETL process");
            console.log(`ğŸ• Current Time: ${currentTime.toISOString()}`);
            console.log(`â° Max End Time: ${maxEndTime.toISOString()}`);
            
            // æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            const progress = await getETLProgress(client);
            console.log("\nğŸ“Š Final ETL Progress (Time Limit Reached):");
            console.log(`   âœ… Completed: ${progress.completed}`);
            console.log(`   âŒ Failed: ${progress.failed}`);
            console.log(`   â³ Pending: ${progress.pending}`);
            console.log(`   ğŸ“Š Total: ${progress.total}`);
            console.log(`   ğŸ“ˆ Success Rate: ${((progress.completed / progress.total) * 100).toFixed(1)}%`);
            
            return;
        }
        
        // è·å–ä¸‹ä¸€æ‰¹å¾…å¤„ç†çš„è‚¡ç¥¨
        const batch = await getNextBatch(client, 50);
        
        if (batch.length === 0) {
            console.log("ğŸ‰ All stocks have been processed for today!");
            
            // æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            const progress = await getETLProgress(client);
            console.log("\nğŸ“Š Final ETL Progress:");
            console.log(`   âœ… Completed: ${progress.completed}`);
            console.log(`   âŒ Failed: ${progress.failed}`);
            console.log(`   ğŸ“Š Total: ${progress.total}`);
            console.log(`   ğŸ“ˆ Success Rate: ${((progress.completed / progress.total) * 100).toFixed(1)}%`);
            
            return;
        }
        
        console.log(`\nğŸ”„ Processing batch of ${batch.length} stocks...`);
        console.log(`ğŸ“‹ Batch ${batch[0].batch_number} - Tickers: ${batch.map(t => t.ticker).join(', ')}`);
        
        // æ ‡è®°ä»»åŠ¡ä¸ºå¤„ç†ä¸­
        const tickers = batch.map(t => t.ticker);
        await markTasksAsProcessing(client, tickers);
        
        // å¤„ç†æ¯åªè‚¡ç¥¨
        let successCount = 0;
        let errorCount = 0;
        
        for (const task of batch) {
            // åœ¨å¤„ç†æ¯åªè‚¡ç¥¨å‰æ£€æŸ¥æ—¶é—´é™åˆ¶
            const currentTime = new Date();
            if (currentTime >= maxEndTime) {
                console.log(`\nâ° Time limit reached during batch processing - stopping at stock ${task.ticker}`);
                console.log(`ğŸ• Current Time: ${currentTime.toISOString()}`);
                break;
            }
            
            const success = await processStock(client, task.ticker, FINNHUB_API_KEY, POLYGON_API_KEY);
            if (success) {
                successCount++;
            } else {
                errorCount++;
            }
            
            // APIé€Ÿç‡é™åˆ¶å»¶è¿Ÿï¼ˆPolygon: 5æ¬¡/åˆ†é’Ÿï¼‰
            if (POLYGON_API_KEY) {
                await new Promise(resolve => setTimeout(resolve, 13000)); // 13ç§’å»¶è¿Ÿ
            } else {
                await new Promise(resolve => setTimeout(resolve, 1000)); // 1ç§’å»¶è¿Ÿ
            }
        }
        
        // æ˜¾ç¤ºæ‰¹æ¬¡ç»“æœ
        console.log(`\nğŸ“Š Batch ${batch[0].batch_number} Results:`);
        console.log(`   âœ… Success: ${successCount}`);
        console.log(`   âŒ Errors: ${errorCount}`);
        console.log(`   ğŸ“ˆ Success Rate: ${((successCount / batch.length) * 100).toFixed(1)}%`);
        
        // æ˜¾ç¤ºæ€»ä½“è¿›åº¦
        const progress = await getETLProgress(client);
        console.log(`\nğŸ“Š Overall ETL Progress:`);
        console.log(`   â³ Pending: ${progress.pending}`);
        console.log(`   ğŸ”„ Processing: ${progress.processing}`);
        console.log(`   âœ… Completed: ${progress.completed}`);
        console.log(`   âŒ Failed: ${progress.failed}`);
        console.log(`   ğŸ“Š Total: ${progress.total}`);
        console.log(`   ğŸ“ˆ Completion Rate: ${((progress.completed / progress.total) * 100).toFixed(1)}%`);
        
        const endTime = new Date();
        const actualRuntime = Math.round((endTime - startTime) / 1000 / 60); // åˆ†é’Ÿ
        console.log(`\nğŸ• End Time: ${endTime.toISOString()}`);
        console.log(`â±ï¸ Actual Runtime: ${actualRuntime} minutes (Max: ${MAX_RUNTIME_MINUTES} minutes)`);
        console.log("===== ETL Smart Batch Processor Completed =====");
        
    } catch (error) {
        console.error("âŒ ETL batch process failed:", error.message);
        console.error("Full error:", error);
        process.exit(1);
    } finally {
        if (client) {
            client.release();
            console.log("Database connection released");
        }
        if (pool) {
            await pool.end();
            console.log("Database pool closed");
        }
    }
}

main();