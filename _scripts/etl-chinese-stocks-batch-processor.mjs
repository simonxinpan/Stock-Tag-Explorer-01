// /_scripts/etl-chinese-stocks-batch-processor.mjs
// ETL Smart Batch Processor for Chinese Stocks - ä¸­æ¦‚è‚¡æ™ºèƒ½åˆ†æ‰¹å¤„ç†å™¨
// æ¯å¤©ä»æ•°æ®åº“åˆå§‹è‚¡ç¥¨å¼€å§‹è¿è¡Œï¼Œæ¯15åˆ†é’Ÿè¿è¡Œä¸€æ¬¡ï¼Œæ¯æ¬¡50åªè‚¡ç¥¨
// å…±è¿è¡Œ10æ¬¡ï¼ˆ150åˆ†é’Ÿï¼‰ï¼Œæ€»è®¡160åˆ†é’Ÿåç»“æŸï¼Œä¸å¾ªç¯è¿è¡Œ
// åƒç´ çº§æ¨¡ä»¿æ ‡æ™®500 ETL Smart Batch Processor

import { Pool } from 'pg';
import 'dotenv/config';
import { getPreviousDayAggs } from './polygon-api.js';

// ä¸­æ¦‚è‚¡ä¸“ç”¨æ•°æ®åº“è¿æ¥
const databaseUrl = process.env.CHINESE_STOCKS_DATABASE_URL;

if (!databaseUrl) {
  console.error(`âŒ CHINESE_STOCKS_DATABASE_URL not found`);
  process.exit(1);
}

const pool = new Pool({ 
    connectionString: databaseUrl, 
    ssl: { rejectUnauthorized: false } 
});

console.log(`ğŸ¯ Market Type: chinese_stocks`);
console.log(`ğŸ”— Database: ${databaseUrl.split('@')[1]?.split('/')[1] || 'Unknown'}`);

// ETLä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€
const ETL_STATUS = {
    PENDING: 'pending',
    PROCESSING: 'processing', 
    COMPLETED: 'completed',
    FAILED: 'failed'
};

// ç¡®ä¿ETLä»»åŠ¡é˜Ÿåˆ—è¡¨å­˜åœ¨
async function ensureETLTaskQueueExists(client) {
    await client.query(`
        CREATE TABLE IF NOT EXISTS etl_task_queue (
            id SERIAL PRIMARY KEY,
            ticker VARCHAR(10) NOT NULL,
            task_date DATE NOT NULL DEFAULT CURRENT_DATE,
            batch_number INTEGER NOT NULL DEFAULT 1,
            status VARCHAR(20) NOT NULL DEFAULT 'pending',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            processed_at TIMESTAMP NULL,
            error_message TEXT NULL,
            UNIQUE(ticker, task_date)
        )
    `);
    
    // åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
    await client.query(`
        CREATE INDEX IF NOT EXISTS idx_etl_task_queue_status_date 
        ON etl_task_queue(status, task_date)
    `);
    
    console.log("âœ… ETL task queue table ensured");
}

// åˆå§‹åŒ–ä»Šæ—¥ETLä»»åŠ¡é˜Ÿåˆ—
async function initializeDailyETLQueue(client) {
    const today = new Date().toISOString().split('T')[0];
    
    // æ£€æŸ¥ä»Šæ—¥æ˜¯å¦å·²åˆå§‹åŒ–
    const { rows: existingTasks } = await client.query(`
        SELECT COUNT(*) as count FROM etl_task_queue 
        WHERE task_date = $1
    `, [today]);
    
    if (parseInt(existingTasks[0].count) > 0) {
        console.log(`ğŸ“‹ Today's ETL queue already initialized (${existingTasks[0].count} tasks)`);
        return;
    }
    
    // è·å–æ‰€æœ‰ä¸­æ¦‚è‚¡å¹¶åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—
    const { rows: stocks } = await client.query(`
        SELECT ticker FROM chinese_stocks 
        ORDER BY ticker
    `);
    
    console.log(`ğŸš€ Initializing ETL queue for ${stocks.length} Chinese stocks...`);
    
    // æ‰¹é‡æ’å…¥ä»»åŠ¡
    const batchSize = 50;
    let batchNumber = 1;
    
    for (let i = 0; i < stocks.length; i += batchSize) {
        const batch = stocks.slice(i, i + batchSize);
        
        const values = batch.map((stock, index) => 
            `('${stock.ticker}', '${today}', ${batchNumber})`
        ).join(', ');
        
        await client.query(`
            INSERT INTO etl_task_queue (ticker, task_date, batch_number)
            VALUES ${values}
            ON CONFLICT (ticker, task_date) DO NOTHING
        `);
        
        batchNumber++;
    }
    
    console.log(`âœ… ETL queue initialized with ${stocks.length} Chinese stocks in ${batchNumber - 1} batches`);
}

// è·å–ä¸‹ä¸€æ‰¹å¾…å¤„ç†çš„è‚¡ç¥¨
async function getNextBatch(client, batchSize = 50) {
    const { rows } = await client.query(`
        SELECT ticker, batch_number FROM etl_task_queue 
        WHERE task_date = CURRENT_DATE AND status = $1
        ORDER BY batch_number, ticker
        LIMIT $2
    `, [ETL_STATUS.PENDING, batchSize]);
    
    return rows;
}

// æ ‡è®°ä»»åŠ¡ä¸ºå¤„ç†ä¸­
async function markTasksAsProcessing(client, tickers) {
    await client.query(`
        UPDATE etl_task_queue 
        SET status = $1, updated_at = CURRENT_TIMESTAMP
        WHERE ticker = ANY($2) AND task_date = CURRENT_DATE
    `, [ETL_STATUS.PROCESSING, tickers]);
}

// æ ‡è®°ä»»åŠ¡ä¸ºå·²å®Œæˆ
async function markTaskAsCompleted(client, ticker) {
    await client.query(`
        UPDATE etl_task_queue 
        SET status = $1, processed_at = CURRENT_TIMESTAMP, updated_at = CURRENT_TIMESTAMP
        WHERE ticker = $2 AND task_date = CURRENT_DATE
    `, [ETL_STATUS.COMPLETED, ticker]);
}

// æ ‡è®°ä»»åŠ¡ä¸ºå¤±è´¥
async function markTaskAsFailed(client, ticker, errorMessage) {
    await client.query(`
        UPDATE etl_task_queue 
        SET status = $1, error_message = $2, updated_at = CURRENT_TIMESTAMP
        WHERE ticker = $3 AND task_date = CURRENT_DATE
    `, [ETL_STATUS.FAILED, errorMessage, ticker]);
}

// è·å–FinnhubæŒ‡æ ‡æ•°æ®
async function getFinnhubMetrics(symbol, apiKey) {
    try {
        const response = await fetch(`https://finnhub.io/api/v1/metric?symbol=${symbol}&metric=all&token=${apiKey}`);
        if (!response.ok) throw new Error(`HTTP ${response.status}`);
        return await response.json();
    } catch (error) {
        console.error(`âŒ Error fetching Finnhub metrics for ${symbol}:`, error.message);
        return null;
    }
}

// è·å–Finnhubå®æ—¶æŠ¥ä»·
async function getFinnhubQuote(symbol, apiKey) {
    try {
        const response = await fetch(`https://finnhub.io/api/v1/quote?symbol=${symbol}&token=${apiKey}`);
        if (!response.ok) throw new Error(`HTTP ${response.status}`);
        return await response.json();
    } catch (error) {
        console.error(`âŒ Error fetching Finnhub quote for ${symbol}:`, error.message);
        return null;
    }
}

// å¤„ç†å•åªè‚¡ç¥¨
async function processStock(client, ticker, finnhubApiKey, polygonApiKey) {
    console.log(`ğŸ“Š Processing ${ticker}...`);
    console.log(`ğŸ“¡ Fetching data for ${ticker}...`);
    
    try {
        // è·å–Finnhubæ•°æ®
        const [quote, metrics] = await Promise.all([
            getFinnhubQuote(ticker, finnhubApiKey),
            getFinnhubMetrics(ticker, finnhubApiKey)
        ]);
        
        if (!quote || quote.c === 0) {
            throw new Error('Invalid quote data from Finnhub');
        }
        
        // è·å–Polygonæ•°æ®ï¼ˆå¦‚æœAPIå¯†é’¥å¯ç”¨ï¼‰
        let polygonData = null;
        if (polygonApiKey) {
            try {
                polygonData = await getPreviousDayAggs(ticker, polygonApiKey);
            } catch (polygonError) {
                console.warn(`âš ï¸ Polygon data unavailable for ${ticker}: ${polygonError.message}`);
            }
        }
        
        // å‡†å¤‡æ›´æ–°æ•°æ®
        const updateData = {
            current_price: quote.c,
            change: quote.d,
            change_percent: quote.dp,
            high: quote.h,
            low: quote.l,
            open: quote.o,
            previous_close: quote.pc,
            updated_at: new Date().toISOString()
        };
        
        // æ·»åŠ FinnhubæŒ‡æ ‡æ•°æ®
        if (metrics && metrics.metric) {
            const m = metrics.metric;
            if (m['52WeekHigh']) updateData.week_52_high = m['52WeekHigh'];
            if (m['52WeekLow']) updateData.week_52_low = m['52WeekLow'];
            if (m.marketCapitalization) updateData.market_cap = m.marketCapitalization * 1000000;
            if (m.peBasicExclExtraTTM) updateData.pe_ratio = m.peBasicExclExtraTTM;
            if (m.pbAnnual) updateData.pb_ratio = m.pbAnnual;
            if (m.psAnnual) updateData.ps_ratio = m.psAnnual;
            if (m.dividendYieldIndicatedAnnual) updateData.dividend_yield = m.dividendYieldIndicatedAnnual;
        }
        
        // æ·»åŠ Polygonæ•°æ®
        if (polygonData && polygonData.results && polygonData.results[0]) {
            const result = polygonData.results[0];
            updateData.volume = result.v;
            updateData.vwap = result.vw;
            updateData.transactions = result.n;
        }
        
        // æ„å»ºæ›´æ–°æŸ¥è¯¢
        const setClause = Object.keys(updateData)
            .map((key, index) => `${key} = $${index + 2}`)
            .join(', ');
        
        const values = [ticker, ...Object.values(updateData)];
        
        // æ›´æ–°æ•°æ®åº“
        await client.query(`
            UPDATE chinese_stocks 
            SET ${setClause}
            WHERE ticker = $1
        `, values);
        
        // æ ‡è®°ä»»åŠ¡ä¸ºå®Œæˆ
        await markTaskAsCompleted(client, ticker);
        
        console.log(`âœ… ${ticker} processed successfully`);
        return true;
        
    } catch (error) {
        console.error(`âŒ Error processing ${ticker}:`, error.message);
        await markTaskAsFailed(client, ticker, error.message);
        return false;
    }
}

// è·å–ETLè¿›åº¦ç»Ÿè®¡
async function getETLProgress(client) {
    const { rows } = await client.query(`
        SELECT 
            status,
            COUNT(*) as count
        FROM etl_task_queue 
        WHERE task_date = CURRENT_DATE
        GROUP BY status
    `);
    
    const progress = {
        pending: 0,
        processing: 0,
        completed: 0,
        failed: 0,
        total: 0
    };
    
    rows.forEach(row => {
        progress[row.status] = parseInt(row.count);
        progress.total += parseInt(row.count);
    });
    
    return progress;
}

async function main() {
    console.log("===== ETL Smart Batch Processor Started =====");
    const startTime = new Date();
    console.log(`ğŸ• Start Time: ${startTime.toISOString()}`);
    
    // è®¾ç½®11åˆ†é’Ÿè¿è¡Œæ—¶é—´é™åˆ¶ï¼ˆåƒç´ çº§æ¨¡ä»¿æ ‡æ™®500ï¼‰
    const MAX_RUNTIME_MINUTES = 11;
    const maxEndTime = new Date(startTime.getTime() + MAX_RUNTIME_MINUTES * 60 * 1000);
    console.log(`â° Max End Time: ${maxEndTime.toISOString()} (${MAX_RUNTIME_MINUTES} minutes limit)`);
    
    const { CHINESE_STOCKS_DATABASE_URL, FINNHUB_API_KEY, POLYGON_API_KEY } = process.env;
    const dbUrl = CHINESE_STOCKS_DATABASE_URL;
    
    // æ£€æŸ¥æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼
    const isTestMode = !dbUrl || dbUrl.includes('username:password') || !FINNHUB_API_KEY || FINNHUB_API_KEY === 'your_finnhub_api_key_here';
    
    if (isTestMode) {
        console.log("âš ï¸ Running in TEST MODE - No valid database connection or API key");
        console.log("âœ… ETL Smart Batch Processor structure validation passed");
        console.log("ğŸ“ To run with real database and API:");
        console.log("   1. Set CHINESE_STOCKS_DATABASE_URL to your Chinese stocks database connection string");
        console.log("   2. Set FINNHUB_API_KEY to your Finnhub API key");
        console.log("   3. Set POLYGON_API_KEY to your Polygon API key (optional)");
        console.log("===== Test completed successfully =====");
        return;
    }
    
    if (!dbUrl || !FINNHUB_API_KEY) {
        console.error("FATAL: Missing CHINESE_STOCKS_DATABASE_URL or FINNHUB_API_KEY environment variables.");
        process.exit(1);
    }
    
    if (!POLYGON_API_KEY) {
        console.warn("âš ï¸ POLYGON_API_KEY not found - Polygon data will be skipped");
    }
    
    console.log("ğŸ”§ ETL Configuration:");
    console.log(`   ğŸ“¦ Batch Size: 50 stocks per batch`);
    console.log(`   â±ï¸ Frequency: Every 15 minutes`);
    console.log(`   ğŸ”„ Max Batches: 1 batch (11 minutes total)`);
    console.log(`   â° Total Runtime: 11 minutes max`);
    console.log(`   ğŸ”‘ APIs: Finnhub âœ…, Polygon ${POLYGON_API_KEY ? 'âœ…' : 'âŒ'}`);
    
    let client;
    try {
        client = await pool.connect();
        console.log("âœ… Database connected successfully");
        
        // ç¡®ä¿ETLä»»åŠ¡é˜Ÿåˆ—è¡¨å­˜åœ¨
        await ensureETLTaskQueueExists(client);
        
        // åˆå§‹åŒ–ä»Šæ—¥ETLä»»åŠ¡é˜Ÿåˆ—
        await initializeDailyETLQueue(client);
        
        // æ£€æŸ¥è¿è¡Œæ—¶é—´é™åˆ¶
        const currentTime = new Date();
        if (currentTime >= maxEndTime) {
            console.log("\nâ° Reached 11-minute runtime limit - stopping ETL process");
            console.log(`ğŸ• Current Time: ${currentTime.toISOString()}`);
            console.log(`â° Max End Time: ${maxEndTime.toISOString()}`);
            
            // æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            const progress = await getETLProgress(client);
            console.log("\nğŸ“Š Final ETL Progress (Time Limit Reached):");
            console.log(`   âœ… Completed: ${progress.completed}`);
            console.log(`   âŒ Failed: ${progress.failed}`);
            console.log(`   â³ Pending: ${progress.pending}`);
            console.log(`   ğŸ“Š Total: ${progress.total}`);
            console.log(`   ğŸ“ˆ Success Rate: ${((progress.completed / progress.total) * 100).toFixed(1)}%`);
            
            return;
        }
        
        // è·å–ä¸‹ä¸€æ‰¹å¾…å¤„ç†çš„è‚¡ç¥¨
        const batch = await getNextBatch(client, 50);
        
        if (batch.length === 0) {
            console.log("ğŸ‰ All Chinese stocks have been processed for today!");
            
            // æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            const progress = await getETLProgress(client);
            console.log("\nğŸ“Š Final ETL Progress:");
            console.log(`   âœ… Completed: ${progress.completed}`);
            console.log(`   âŒ Failed: ${progress.failed}`);
            console.log(`   ğŸ“Š Total: ${progress.total}`);
            console.log(`   ğŸ“ˆ Success Rate: ${((progress.completed / progress.total) * 100).toFixed(1)}%`);
            
            return;
        }
        
        console.log(`\nğŸ”„ Processing batch of ${batch.length} stocks...`);
        console.log(`ğŸ“‹ Batch ${batch[0].batch_number} - Tickers: ${batch.map(t => t.ticker).join(', ')}`);
        
        // æ ‡è®°ä»»åŠ¡ä¸ºå¤„ç†ä¸­
        const tickers = batch.map(t => t.ticker);
        await markTasksAsProcessing(client, tickers);
        
        // å¤„ç†æ¯åªè‚¡ç¥¨
        let successCount = 0;
        let errorCount = 0;
        
        for (const task of batch) {
            // åœ¨å¤„ç†æ¯åªè‚¡ç¥¨å‰æ£€æŸ¥æ—¶é—´é™åˆ¶
            const currentTime = new Date();
            if (currentTime >= maxEndTime) {
                console.log(`\nâ° Time limit reached during batch processing - stopping at stock ${task.ticker}`);
                console.log(`ğŸ• Current Time: ${currentTime.toISOString()}`);
                break;
            }
            
            const success = await processStock(client, task.ticker, FINNHUB_API_KEY, POLYGON_API_KEY);
            if (success) {
                successCount++;
            } else {
                errorCount++;
            }
            
            // APIé€Ÿç‡é™åˆ¶å»¶è¿Ÿï¼ˆPolygon: 5æ¬¡/åˆ†é’Ÿï¼‰
            if (POLYGON_API_KEY) {
                await new Promise(resolve => setTimeout(resolve, 13000)); // 13ç§’å»¶è¿Ÿ
            } else {
                await new Promise(resolve => setTimeout(resolve, 1000)); // 1ç§’å»¶è¿Ÿ
            }
        }
        
        // æ˜¾ç¤ºæ‰¹æ¬¡ç»“æœ
        console.log(`\nğŸ“Š Batch ${batch[0].batch_number} Results:`);
        console.log(`   âœ… Success: ${successCount}`);
        console.log(`   âŒ Errors: ${errorCount}`);
        console.log(`   ğŸ“ˆ Success Rate: ${((successCount / batch.length) * 100).toFixed(1)}%`);
        
        // æ˜¾ç¤ºæ€»ä½“è¿›åº¦
        const progress = await getETLProgress(client);
        console.log(`\nğŸ“Š Overall ETL Progress:`);
        console.log(`   â³ Pending: ${progress.pending}`);
        console.log(`   ğŸ”„ Processing: ${progress.processing}`);
        console.log(`   âœ… Completed: ${progress.completed}`);
        console.log(`   âŒ Failed: ${progress.failed}`);
        console.log(`   ğŸ“Š Total: ${progress.total}`);
        console.log(`   ğŸ“ˆ Completion Rate: ${((progress.completed / progress.total) * 100).toFixed(1)}%`);
        
        const endTime = new Date();
        const actualRuntime = Math.round((endTime - startTime) / 1000 / 60); // åˆ†é’Ÿ
        console.log(`\nğŸ• End Time: ${endTime.toISOString()}`);
        console.log(`â±ï¸ Actual Runtime: ${actualRuntime} minutes (Max: ${MAX_RUNTIME_MINUTES} minutes)`);
        console.log("===== ETL Smart Batch Processor Completed =====");
        
    } catch (error) {
        console.error("âŒ ETL batch process failed:", error.message);
        console.error("Full error:", error);
        process.exit(1);
    } finally {
        if (client) {
            client.release();
            console.log("Database connection released");
        }
        if (pool) {
            await pool.end();
            console.log("Database pool closed");
        }
    }
}

main();